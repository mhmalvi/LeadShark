# Google Sheets Intelligence Pipeline - Setup Guide

## ğŸš€ Quick Start

This guide will help you set up the automated Google Sheets intelligence processing system.

## ğŸ“‹ Prerequisites

1. **Python 3.8+** installed
2. **Google Cloud Account** (free tier sufficient)
3. **Google Sheets** with your data
4. **Internet connection** for API calls

## ğŸ›  Step-by-Step Setup

### Step 1: Install Required Packages

```bash
pip install google-auth google-auth-oauthlib google-auth-httplib2
pip install google-api-python-client
pip install requests beautifulsoup4 pandas python-dotenv
```

### Step 2: Google Cloud Setup

1. **Go to Google Cloud Console**
   - Visit: https://console.cloud.google.com/
   - Create a new project or select existing one

2. **Enable Google Sheets API**
   - Go to "APIs & Services" > "Library"
   - Search for "Google Sheets API"
   - Click "Enable"

3. **Create Service Account**
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "Service Account"
   - Fill in service account details
   - Click "Create and Continue"
   - Skip role assignment (or assign "Editor" for full access)
   - Click "Done"

4. **Generate Credentials JSON**
   - Click on the created service account
   - Go to "Keys" tab
   - Click "Add Key" > "Create new key"
   - Select "JSON" format
   - Download the file
   - **Important:** Keep this file secure!

### Step 3: Google Sheets Preparation

1. **Share Your Sheet**
   - Open your Google Sheet
   - Click "Share" button
   - Add the service account email (found in the JSON file)
   - Give it "Editor" permissions
   - Click "Send"

2. **Get Sheet ID**
   - From your Google Sheets URL: `https://docs.google.com/spreadsheets/d/SHEET_ID/edit`
   - Copy the `SHEET_ID` part

### Step 4: Environment Configuration

Create a `.env` file in your project directory:

```env
# Google Sheets Configuration
GOOGLE_SHEETS_CREDENTIALS_PATH=./path/to/your/credentials.json
GOOGLE_SHEET_ID=your_sheet_id_here

# Optional API Keys (for enhanced features)
WHOISXML_API_KEY=your_whoisxml_key_here

# Processing Configuration
MAX_ROWS_PER_BATCH=50
START_ROW=2
PROCESSING_DELAY=2
```

### Step 5: Update Configuration

Edit the main processor file:

```python
# In google_sheets_processor.py
CREDENTIALS_PATH = "path/to/your/credentials.json"
SHEET_ID = "your_google_sheet_id_here"
```

## ğŸƒâ€â™‚ï¸ Running the System

### Test Run (First 5 rows)
```bash
python google_sheets_processor.py
```

### Full Processing
```python
from google_sheets_processor import GoogleSheetsIntelligenceProcessor

# Initialize
processor = GoogleSheetsIntelligenceProcessor(
    credentials_path="your_credentials.json",
    sheet_id="your_sheet_id"
)

# Authenticate
if processor.authenticate():
    # Process all rows (or specify max_rows)
    results = processor.process_sheet(start_row=2, max_rows=None)
    print("Processing completed:", results)
```

## ğŸ“Š Expected Results

### New Columns Added to Your Sheet
1. **Column: Enhanced Intelligence Report** 
   - Complete markdown analysis for each person/company
   - Includes web scraping results, API enrichment, recommendations

2. **Column: Processing Status**
   - "completed", "failed", "processing", "skipped"

3. **Column: Last Updated**
   - Timestamp of when the row was processed

### Sample Report Output
```markdown
# Intelligence Report: John Smith

**Report Generated:** 2025-01-15 10:30:00
**Organization:** TechCorp Solutions
**Title:** VP Marketing

## ğŸ‘¤ Person Profile
- **Name:** John Smith
- **Gender:** Male (95% confidence)
- **Email:** Deliverable âœ…

## ğŸ¢ Organization Analysis  
- **Website Status:** âœ… Active
- **LinkedIn:** âœ… Professional presence
- **Industry:** Technology, Marketing

## ğŸ¯ Engagement Recommendations
1. Connect via LinkedIn for B2B outreach
2. Review company website for service alignment
3. Verify email deliverability confirmed
```

## âš¡ Performance Expectations

### Processing Speed
- **Per Row:** 30-60 seconds (includes respectful delays)
- **100 Rows:** 50-100 minutes
- **1000 Rows:** 8-16 hours

### Success Rates
- **Website Scraping:** 90-95% success
- **LinkedIn Company Pages:** 80-90% success  
- **Personal LinkedIn:** 10-20% success (privacy protected)
- **Social Media:** 60-80% success
- **API Enrichment:** 85-95% success

## ğŸ”§ Troubleshooting

### Common Issues

**Authentication Failed**
```
Error: Authentication failed
Solution: Check credentials.json path and Google Sheets sharing permissions
```

**Rate Limiting**
```
Error: HTTP 429 or 403
Solution: System automatically handles with exponential backoff
```

**Empty Results**  
```
Issue: No content extracted
Solution: Check if URLs are valid and publicly accessible
```

**Sheet Write Errors**
```
Error: Permission denied
Solution: Ensure service account has "Editor" permissions on the sheet
```

### Debug Mode

Enable detailed logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ Optimization Tips

### For Large Datasets (1000+ rows)

1. **Batch Processing**
   ```python
   # Process in chunks of 50 rows
   for i in range(0, total_rows, 50):
       results = processor.process_sheet(
           start_row=i+2, 
           max_rows=50
       )
   ```

2. **Resume Capability**
   - System automatically tracks processed rows
   - Can resume from interruption
   - Skips already completed rows

3. **Rate Limiting**
   - Built-in delays between requests
   - Exponential backoff for rate limits
   - Platform-specific optimizations

## ğŸ”’ Security & Privacy

### Data Protection
- Only processes publicly available information
- Respects robots.txt and platform policies
- No credential storage in sheets
- Secure API key management

### Rate Limiting
- 2-4 second delays between requests
- Respectful of platform terms of service
- Automatic backoff for rate limits

### Privacy Compliance
- Does not attempt to bypass privacy settings
- Logs blocked/protected content appropriately
- Follows ethical scraping practices

## ğŸ’° Cost Breakdown

### Free Tier Usage
- **Google Sheets API:** 100 requests/100 seconds (Free)
- **Genderize.io:** 500 requests/month (Free)  
- **GitHub API:** 60 requests/hour (Free)
- **Email Verification:** Limited free usage

### Estimated Costs (1000 rows)
- **Processing Time:** 8-16 hours
- **API Costs:** $0-5 (mostly free tier)
- **Compute:** Minimal (runs on any laptop)

## ğŸ¯ Success Metrics

### Quality Indicators
- **>90%** successful URL processing
- **>85%** API enrichment success
- **>95%** report completeness
- **<5%** unrecoverable errors

### Performance Targets
- **60-120** rows per hour
- **<2GB** memory usage
- **100%** resume capability
- **Automated** error recovery

## ğŸ“ Support & Maintenance

### Log Files
- `sheets_processing.log` - Detailed processing logs
- `enriched_data.json` - API results backup
- Error tracking and recovery suggestions

### Monitoring
- Real-time progress logging
- API quota usage tracking  
- Error rate monitoring
- Performance metrics

## ğŸ”„ Continuous Improvement

### Future Enhancements
- Additional API integrations
- Enhanced report formatting
- Advanced filtering options
- Performance optimizations

### Customization
- Modify report templates
- Add custom API endpoints
- Adjust rate limiting parameters
- Extend platform support

---

**Ready to Start?**

1. âœ… Install packages
2. âœ… Setup Google Cloud credentials  
3. âœ… Configure environment variables
4. âœ… Run test with 5 rows
5. âœ… Scale to full dataset

Your automated intelligence pipeline is ready! ğŸš€